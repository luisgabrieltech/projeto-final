# ğŸš§ Sistema de PrevisÃ£o de Tipos de Acidentes RodoviÃ¡rios

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![XGBoost](https://img.shields.io/badge/XGBoost-2.0%2B-orange)](https://xgboost.readthedocs.io/)
[![PySpark](https://img.shields.io/badge/PySpark-3.5%2B-yellow)](https://spark.apache.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.32%2B-red)](https://streamlit.io/)
[![Dash](https://img.shields.io/badge/Dash-3.0%2B-lightblue)](https://dash.plotly.com/)

## ğŸ“‹ Sobre o Projeto

Este sistema utiliza **Machine Learning** para prever tipos de acidentes rodoviÃ¡rios com base em dados histÃ³ricos da **PolÃ­cia RodoviÃ¡ria Federal (PRF)**. O objetivo Ã© auxiliar na prevenÃ§Ã£o de acidentes e no planejamento estratÃ©gico de recursos de seguranÃ§a rodoviÃ¡ria.

### ğŸ¯ Objetivos
- Prever o tipo de acidente (ColisÃ£o, Atropelamento, Capotamento, etc.)
- Auxiliar no planejamento preventivo de recursos
- Fornecer insights sobre padrÃµes de acidentes
- Criar dashboards interativos para anÃ¡lise de dados

### ğŸ† Principais CaracterÃ­sticas
- **Modelo XGBoost** com 70% de acurÃ¡cia
- **Pipeline completo** de processamento de dados com PySpark
- **Dashboards interativos** em Dash e Streamlit
- **Testes automatizados** com pytest
- **AnÃ¡lise exploratÃ³ria** em Jupyter Notebooks

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **Machine Learning**: XGBoost, Scikit-learn
- **Processamento de Dados**: PySpark, Pandas
- **VisualizaÃ§Ã£o**: Plotly, Dash, Streamlit
- **Testes**: Pytest
- **AnÃ¡lise**: Jupyter Notebooks

## ğŸ“‚ Estrutura do Projeto

```
projeto-final/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ acidentes.csv           # Dados brutos da PRF
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ acidentes_tratado.csv   # Dados processados
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.pkl                   # Modelo treinado XGBoost
â”‚   â”œâ”€â”€ label_encoders.pkl          # Encoders para variÃ¡veis categÃ³ricas
â”‚   â”œâ”€â”€ target_encoder.pkl          # Encoder para variÃ¡vel target
â”‚   â””â”€â”€ classification_report.txt   # RelatÃ³rio de desempenho
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing.py          # Processamento de dados (PySpark)
â”‚   â”œâ”€â”€ ml_pipeline.py             # Pipeline de ML
â”‚   â”œâ”€â”€ predict.py                 # FunÃ§Ãµes de prediÃ§Ã£o
â”‚   â”œâ”€â”€ dashboard_dados.py         # Dashboard de anÃ¡lise (Dash)
â”‚   â””â”€â”€ dashboard_predict.py       # Dashboard de prediÃ§Ã£o (Streamlit)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda.ipynb                  # AnÃ¡lise exploratÃ³ria
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py                # ConfiguraÃ§Ãµes de teste
â”‚   â””â”€â”€ test_predict.py            # Testes do modelo
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ relatorio.md               # RelatÃ³rio tÃ©cnico completo
â””â”€â”€ requirements.txt               # DependÃªncias
```

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o RepositÃ³rio
```bash
git clone https://github.com/luisgabrieltech/projeto-final.git
cd projeto-final
```

### 2. Crie um Ambiente Virtual
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

### 3. Instale as DependÃªncias
```bash
pip install -r requirements.txt
```

### 4. ConfiguraÃ§Ã£o do Java (para PySpark)
Certifique-se de ter o Java 8+ instalado para usar o PySpark:
```bash
java -version
```

## ğŸ“Š Como Usar

### 1. Processamento dos Dados
```bash
# Processa os dados brutos da PRF
python src/data_processing.py
```

### 2. Treinamento do Modelo
```bash
# Treina o modelo XGBoost e salva os artefatos
python src/ml_pipeline.py
```

### 3. Dashboard de AnÃ¡lise de Dados
```bash
# Inicia o dashboard interativo para anÃ¡lise exploratÃ³ria
python src/dashboard_dados.py
```
Acesse: http://localhost:8050

### 4. Dashboard de PrediÃ§Ã£o
```bash
# Inicia a interface de prediÃ§Ã£o em tempo real
streamlit run src/dashboard_predict.py
```
Acesse: http://localhost:8501

### 5. PrediÃ§Ã£o via API
```python
from src.predict import prever_acidente

# Exemplo de uso
entrada = {
    "hora": 15,
    "uf": "SP", 
    "br": 116,
    "condicao_metereologica": "CÃ©u Claro",
    "causa_acidente": "ReaÃ§Ã£o tardia ou ineficiente do condutor",
    "data": "2025-06-15"
}

resultado = prever_acidente(entrada)
print(f"Tipo de acidente previsto: {resultado}")
```

## ğŸ“ˆ Modelo de Machine Learning

### Algoritmo
- **XGBoost Classifier** otimizado para classificaÃ§Ã£o multiclasse

### Features Utilizadas
- `hora`: Hora do dia (0-23)
- `uf`: Estado onde ocorreu o acidente
- `br`: NÃºmero da rodovia federal
- `condicao_metereologica`: CondiÃ§Ãµes climÃ¡ticas
- `causa_acidente`: Causa principal do acidente
- `periodo_dia`: PerÃ­odo (Madrugada, ManhÃ£, Tarde, Noite)
- `dia_semana`: Dia da semana

### Classes Previstas
1. **ColisÃ£o** - Diversos tipos de colisÃµes
2. **Atropelamento** - Atropelamento de pedestres e animais
3. **Capotamento/Tombamento** - Acidentes com capotamento
4. **Outros** - Outros tipos de acidentes

### Desempenho
- **AcurÃ¡cia Geral**: 70%
- **Melhor Classe**: ColisÃ£o (F1-score: 0.82)
- **Maior Desafio**: Capotamento/Tombamento (F1-score: 0.13)

## ğŸ§ª Testes

Execute os testes automatizados:
```bash
# Executa todos os testes
pytest

# Executa testes com cobertura
pytest --cov=src

# Executa testes especÃ­ficos
pytest tests/test_predict.py -v
```

## ğŸ“Š Dashboards

### Dashboard de AnÃ¡lise (Dash)
- VisualizaÃ§Ãµes interativas dos dados histÃ³ricos
- GrÃ¡ficos de distribuiÃ§Ã£o por causa, estado, hora e tipo
- Interface responsiva com Bootstrap

### Dashboard de PrediÃ§Ã£o (Streamlit) 
- Interface amigÃ¡vel para fazer prediÃ§Ãµes
- SeleÃ§Ã£o interativa de parÃ¢metros
- Resultado em tempo real

## ğŸ“‹ AnÃ¡lise ExploratÃ³ria

Execute o notebook de anÃ¡lise exploratÃ³ria:
```bash
jupyter lab notebooks/eda.ipynb
```

O notebook contÃ©m:
- AnÃ¡lise estatÃ­stica dos dados
- VisualizaÃ§Ãµes avanÃ§adas
- CorrelaÃ§Ãµes entre variÃ¡veis
- Insights sobre padrÃµes de acidentes

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“‹ Requisitos do Sistema

- **Python**: 3.8+
- **Java**: 8+ (para PySpark)
- **MemÃ³ria RAM**: 4GB+ recomendado
- **EspaÃ§o em Disco**: 1GB+ para dados e modelos

## ğŸ› ResoluÃ§Ã£o de Problemas

### Erro com PySpark
```bash
# Configure as variÃ¡veis de ambiente
export JAVA_HOME=/path/to/java
export SPARK_HOME=/path/to/spark
```

### Erro de DependÃªncias
```bash
# Reinstale as dependÃªncias
pip install --upgrade -r requirements.txt
```

### Modelo nÃ£o Encontrado
```bash
# Execute o pipeline de ML primeiro
python src/ml_pipeline.py
```

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ™ Agradecimentos

- **PRF (PolÃ­cia RodoviÃ¡ria Federal)** pelos dados pÃºblicos
- **Comunidade Open Source** pelas ferramentas utilizadas
- **Faculdade** pelo suporte acadÃªmico

## ğŸ“š ReferÃªncias

- [Dados Abertos PRF](https://portal.prf.gov.br/dados-abertos)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [Dash Documentation](https://dash.plotly.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)

---

â­ **Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela!** â­